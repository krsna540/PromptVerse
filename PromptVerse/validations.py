from better_profanity import profanity
import tiktoken


def check_profanity(llm_response: str) -> bool:
    """to check profanity or any abusive or vulgar language came as response from pronpt
    Args:
        llm_response (str): response generated by LLM model for user prompt
    Returns:
        bool: whether response came from llm has profanity or not
    """
    return profanity.contains_profanity(llm_response)


def topic_check(options: list, llm_response: str) -> bool:
    """topic_check - to check if llm response is in provided topics/categories

    Args:
        options (list): list of categories
        llm_response (str): response generated by LLM model for user prompt

    Returns:
        bool: True llm response is in provided topics/categories
    """
    topic_available = False
    options = (options.replace("'", "").replace(
        "[", "").replace("]", "").replace('"', '')).split(",")

    for topic in options:
        if topic.lower() in llm_response.lower():

            topic_available = True
            break
    return topic_available


def num_tokens_from_string(string: str, encoding_name: str) -> int:
    encoding = tiktoken.get_encoding(encoding_name)
    print(string)
    num_tokens = len(encoding.encode(string))
    return num_tokens